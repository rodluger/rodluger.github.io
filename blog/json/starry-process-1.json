{
    "post": {
        "title": "An interpretable Gaussian process for stellar rotation (Part 1)",
        "date": "September 24 2020",
        "publish": false,
        "author": {
            "name": "Rodrigo Luger",
            "url": "../about.html",
            "image": "../images/rodrigo-luger-avatar.jpg",
            "about": "I'm a Flatiron Fellow at the CCA in New York City, working on a variety of things related to exoplanets, stars, and astronomical data analysis. I'm interested in systematics de-trending, the search for and characterization of potentially habitable exoplanets, and the mapping of stellar and exoplanetary surfaces from photometric and spectroscopic datasets. Outside the office I love to hike, bike, swim, craft lattes, faulty parallelism, and Oxford commas."
        },
        "banner": "images/starry-process.jpg",
        "summary": "As I discussed in my <a href='2020-09-17.html'>previous post</a>, the information content of stellar light curves can be exceptionally tiny, owing to the large number of degeneracies when projecting from a two-dimensional space (the stellar surface) to a one-dimensional curve (the flux timeseries). Instead of trying to produce a definitive map of a stellar surface from a light curve, we can instead model the surface as a statistical process. In this post, I discuss ongoing work to develop a Gaussian process for stellar light curves whose hyperparameters are rooted in statistical properties of the stellar surface.",
        "contents": [
            "An important fact about the degeneracies in phase curves is that they are strong functions of the star's (or planet's) inclination. The surface modes we can constrain when the axis of rotation is at a right angle with respect to the line of sight (i.e., an inclination of 90&deg;) are very different from those at inclinations of 60&deg; or 45&deg;. Since stellar inclinations are randomly distributed, we're able to learn slightly different things about the surfaces of different stars. This suggests that if we had enough stars, we could learn a lot more about the collective surface properties of that group of stars than we could for any individual star. <span style='font-weight: 400;'>This is the power of ensemble statistics: while individual light curves are only weakly informative, lots of light curves analyzed jointly can be extremely informative about statistics of the population.</span>",
            "But how do we harness this ensemble information? Thanks to <span style='font-style:italic;'>Kepler</span> and <span style='font-style:italic;'>TESS</span>, we now have access to hundreds of thousands of stellar light curves. We could imagine a scheme in which we select 1,000 light curves of \"similar\" <span style='font-style:italic;'>TESS</span> stars (say, 1,000 early M dwarfs with similar metallicity and rotation periods), and simultaneously fit for their surface maps. We do this simultaneously because we want to tie the individual maps together with priors shared by all stars: for example, the mean and variance of the spot size distribution, the mean and variance of the spot latitude distribution, etc. These priors are the <span style='font-style:italic;'>hyperparameters</span> of our model, the population-level statistics that we actually care about (see <a href='#Figure1'>Figure 1</a>).",
            {
                "src": "images/pgm.jpg",
                "caption": "A probabilistic graphical model for stellar light curves. We model the surface of each star \\(n\\) in a population \\(p\\) of similar stars as the sum of \\(k=1..K\\) star spots. The properties of each spot (size, latitude, and contrast) are draws from a parent (hyper)distribution, whose means and variances are the global hyperparameters we wish to constrain.",
                "css_classes": [
                    "small"
                ]
            },
            "In order for this scheme to work, we need to be able to compute the marginal likelihood function for each light curve: the probability that the observed data was drawn from a distribution with given hyperparameters. This is different from the probability of the data given a <span style='font-style:italic;'>specific</span> configuration of features on the surface of the star; rather, it is the probability <span style='font-style:italic;'>integrated</span> (or marginalized) over all possible surface brightness distributions consistent with the hyperparameters of the spot distribution. This is a tough integral no matter how you parametrize it. If we were to model stellar surfaces with discrete circular spots as in the figure above, we'd need to integrate over dozens &mdash; or maybe even hundreds &mdash; of free parameters <span style='font-style:italic;'>for each star</span>. That's a very tall order when your sample consists of 1,000 stars, even for modern MCMC and approximate inference methods.",
            "Fortunately, there is one class of integrals that are very easy to compute: the integrals of Gaussian distributions. If the distribution from which the surface maps of the stars is drawn is a (multidimensional) Gaussian, we can <span style='font-style:italic;'>analytically</span> compute the required marginal likelihoods, turning an intractable high-dimensional integral into an easy sequence of operations in linear algebra. This is precisely the motivation behind <a href='https://en.wikipedia.org/wiki/Gaussian_process'>Gaussian processes</a>.",
            "Nowadays, Gaussian processes are commonly used to model stellar variability, especially because of how efficient and simple to use they are. However, the choices made when fitting stellar light curves with GPs are often arbitrary: in particular, the <a href='https://scikit-learn.org/stable/modules/gaussian_process.html#gp-kernels'>kernel</a> describing the covariance matrix is usually chosen to enforce a certain amount of smoothness in the model, but its functional form isn't inherently related to the star spots giving rise to the light curve variability. Nor are the kernel (hyper)parameters directly related to actual physical properties of the stars they are used to model (with the exception of the period, which is closely related to the rotation period of the star). An example of this is the <a href='https://scikit-learn.org/stable/modules/gaussian_process.html#exp-sine-squared-kernel'>ExpSineSquared</a> kernel sometimes used for stellar light curves, which depends on a period parameter and a length scale parameter. The period may be interpreted as the rotation period of the star, but the meaning of the length scale is less obvious. It is <span style='font-style:italic;'>related</span> to the autocorrelation length of the light curve, which is in turn <span style='font-style:italic;'>related</span> to the autocorrelation length of features on the surface. But if we were given a light curve and tried to infer this length scale parameter (either by optimization or sampling), we wouldn't really know what to do with the value we obtain. For example, a short length scale <span style='font-style:italic;'>could</span> mean a surface covered in very small spots, or it could mean spots at a very low latitude, such that individual spots are only visible for a brief moment before returning to the backside of the star. Since our kernel wasn't specifically designed to capture stellar variability, we can't use it to learn anything useful about the spots on the surface.",
            "Enter <a href='https://github.com/rodluger/starry'>starry</a>, the light curve modeling package I developed. <a href='https://github.com/rodluger/starry'>starry</a> models the surfaces of stars as linear combinations of <a href='https://en.wikipedia.org/wiki/Spherical_harmonics'>spherical harmonics</a>. One of the (many) cool things about spherical harmonics is their close relationship to Gaussian processes (sometimes called <a href='https://link.springer.com/chapter/10.1007%2F978-1-4614-3508-2_5'>Gaussian Random Fields</a>) on the sphere. If we consider expansions up to spherical harmonic degree \\(l\\), we can build a GP by constructing a covariance matrix of shape \\( (l + 1)^2 \\times (l + 1)^2 \\). Cosmologists typically consider diagonal matrices, which define an isotropic Gaussian process whose power spectrum is related to the diagonal entries of this matrix. Drawing samples from this GP will yield vectors of spherical harmonic coefficients corresponding to different realizations of (say) the matter distribution in the Universe or (say) the surface brightness distribution of a stellar surface, conditioned on a given power spectrum. Alternatively, given an observation of one of these quantities (in our case, a stellar light curve), we can use the GP to compute the marginal likelihood of the dataset: the probability that this dataset was generated from the GP, integrating (marginalizing) over all possible configurations consistent with the parameters of the kernel.",
            "In the cosmologists' case, an isotropic GP is often desirable, since (we believe) the Universe is isotropic on large scales. But in our case, we have reason to believe stellar surfaces are anisotropic, since the combined effects of rotation and magnetic fields tend to confine star spots to certain latitudes. On the sun, most spots form at mid-latitudes and migrate toward the equator over the course of a solar cycle. On other stars this may very well be different, but it is reasonable to assume that the azimuthal distribution of features may in general be different than the polar distribution: i.e., an anisotropic distribution.",
            "In order to capture this anisotropy, we'll have to add off-diagonal terms to our covariance matrix."
        ]
    }
}